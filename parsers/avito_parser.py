import logging
from bs4 import BeautifulSoup
from utils import get_random_user_agent, get_random_proxy, safe_request
import urllib.parse
import time
import re
import random
from datetime import datetime


class AvitoParser:
    def __init__(self, make, model, year=None):
        self.make = make
        self.model = model
        self.year = year
        self.base_url = "https://www.avito.ru"
        self.logger = logging.getLogger(__name__)

    def parse(self):
        encoded_make = urllib.parse.quote(self.make.lower())
        encoded_model = urllib.parse.quote(self.model.lower())
        prices = []
        page = 1

        start_year = self.year if self.year else 2000
        end_year = datetime.now().year

        while len(prices) < 100:
            search_url = (
                f"{self.base_url}/moskva/avtomobili/"
                f"{encoded_make}/{encoded_model}/"
                f"?p={page}&radius=1000&searchRadius=1000"
            )
            headers = {
                "User-Agent": get_random_user_agent(),
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                "Upgrade-Insecure-Requests": "1",
                "Connection": "keep-alive",
                "Cache-Control": "max-age=0"
            }
            proxy = get_random_proxy()

            response = safe_request(search_url, headers, proxy)
            if not response:
                self.logger.error(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñƒ {page}")
                break

            soup = BeautifulSoup(response.text, "html.parser")
            new_prices = []

            # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ñ†ÐµÐ½Ñ‹ Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð³Ð¾Ð´ Ð²Ñ‹Ð¿ÑƒÑÐºÐ°
            for item in soup.select(".iva-item-content-OWwoq"):
                name_tag = item.select_one('h3[itemprop="name"]')
                if not name_tag:
                    self.logger.debug(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: ÐžÐ±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ Ð±ÐµÐ· Ð¸Ð¼ÐµÐ½Ð¸")
                    continue

                name_text = name_tag.get_text(strip=True)
                match = re.search(r'\b(\d{4})\b', name_text)
                if match:
                    car_year = int(match.group(1))
                    if not (start_year <= car_year <= end_year):
                        self.logger.debug(
                            f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: ÐžÐ±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ {name_text}, Ð³Ð¾Ð´ {car_year} Ð½Ðµ Ð² Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ðµ [{start_year}-{end_year}]"
                        )
                        continue
                else:
                    self.logger.debug(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: ÐžÐ±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ {name_text} Ð±ÐµÐ· Ð³Ð¾Ð´Ð° Ð²Ñ‹Ð¿ÑƒÑÐºÐ°")
                    continue

                price_tag = item.select_one(".iva-item-priceStep-TIzu3")
                if not price_tag:
                    self.logger.debug(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: ÐžÐ±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ {name_text} Ð±ÐµÐ· Ñ†ÐµÐ½Ñ‹")
                    continue

                price_meta = price_tag.select_one("meta[itemprop='price']")
                if price_meta:
                    price = int(price_meta["content"])
                    if 100_000 <= price <= 200_000_000:
                        new_prices.append(price)
                        self.logger.debug(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: {name_text}, {car_year}, Ñ†ÐµÐ½Ð° {price} Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð°")
                    else:
                        self.logger.debug(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: ÐžÐ±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ðµ {name_text}, Ñ†ÐµÐ½Ð° {price} Ð²Ð½Ðµ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð°")
                else:
                    try:
                        price_text = price_tag.get_text(strip=True).split("â‚½")[0]
                        price_str = "".join(filter(str.isdigit, price_text))
                        if price_str:
                            price = int(price_str)
                            if 100_000 <= price <= 200_000_000:
                                new_prices.append(price)
                                self.logger.debug(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: {name_text}, {car_year}, Ñ†ÐµÐ½Ð° {price} Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð°")
                            else:
                                self.logger.debug(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: Ð¦ÐµÐ½Ð° {price} Ð²Ð½Ðµ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ð°")
                    except (ValueError, AttributeError):
                        self.logger.warning(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ñ†ÐµÐ½Ñ‹ Ð´Ð»Ñ Ð¾Ð±ÑŠÑÐ²Ð»ÐµÐ½Ð¸Ñ {name_text}")

            prices.extend(new_prices)
            self.logger.info(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {page}: Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¾ {len(new_prices)} Ñ†ÐµÐ½")

            # ðŸ”¹ **ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ñ ÐºÐ½Ð¾Ð¿ÐºÐ¸ "Ð¡Ð»ÐµÐ´ÑƒÑŽÑ‰Ð°Ñ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ð°"**
            next_page = soup.select_one('[data-marker="pagination-button/nextPage"]')
            if next_page:
                page += 1
                time.sleep(random.uniform(10, 15))  # Ð£Ð²ÐµÐ»Ð¸Ñ‡ÐµÐ½Ð½Ð°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð¼ÐµÐ¶Ð´Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸
            else:
                self.logger.info("ÐšÐ¾Ð½ÐµÑ† Ð¿Ð°Ð³Ð¸Ð½Ð°Ñ†Ð¸Ð¸, Ð·Ð°Ð²ÐµÑ€ÑˆÐ°ÐµÐ¼ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³.")
                break  # ðŸ”¹ ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ†Ð¸ÐºÐ», ÐµÑÐ»Ð¸ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ† Ð±Ð¾Ð»ÑŒÑˆÐµ Ð½ÐµÑ‚

        self.logger.info(f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ {page} ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†, Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ {len(prices)} Ñ†ÐµÐ½")

        # ÐŸÐ¾Ð¼ÐµÑ‚ÐºÐ°, ÐµÑÐ»Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¼ÐµÐ½ÐµÐµ 100 Ñ†ÐµÐ½
        if len(prices) < 100:
            self.logger.warning(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð²ÑÐµÐ³Ð¾ {len(prices)} Ñ†ÐµÐ½, Ñ€Ð°ÑÑ‡ÐµÑ‚ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÑÑ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¸Ð¼ÐµÑŽÑ‰Ð¸Ñ…ÑÑ Ð´Ð°Ð½Ð½Ñ‹Ñ….")

        return prices[:100]
